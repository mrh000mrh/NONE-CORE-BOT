import re

def extract_from_html(html_content):
    configs = []

    # regex Ø¨Ø±Ø§ÛŒ Ù„ÛŒÙ†Ú© Ú©Ø§Ù…Ù„ ØªØ§ # ÛŒØ§ Ø§Ù†ØªÙ‡Ø§
    link_pattern = r'(vless|vmess|trojan|ss|ssr|tuic|hysteria2?|vlesss?|vmesss?|trojans?|shadowsocks|ssr|hy2?)://(.*?)(#|$)'
    matches = re.findall(link_pattern, html_content, re.IGNORECASE | re.DOTALL)

    for proto, params, end in matches:
        link = proto + '://' + params + end
        link = link.strip()
        if len(link) < 30:
            continue

        location = "Unknown"
        ping = "Unknown"
        remark = "@nonecorebot"

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÙˆÚ©ÛŒØ´Ù† Ø§Ø² Ù…ØªÙ†
        loc_match = re.search(r'(Ù„ÙˆÚ©ÛŒØ´Ù†|location|country|Ú©Ø´ÙˆØ±|Ø³Ø±ÙˆØ±|server|Ù…Ù†Ø·Ù‚Ù‡):?\s*([A-Za-z\s\-ØŒðŸ‡¦-ðŸ‡¿]{2,30})', html_content, re.IGNORECASE | re.UNICODE)
        if loc_match:
            location = loc_match.group(2).strip().replace('ØŒ', '')

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù¾ÛŒÙ†Ú¯
        ping_match = re.search(r'(Ù¾ÛŒÙ†Ú¯|ping|latency):?\s*(\d+)\s*(ms|Ù…ÛŒÙ„ÛŒâ€ŒØ«Ø§Ù†ÛŒÙ‡)?', html_content, re.IGNORECASE)
        if ping_match:
            ping = ping_match.group(2)

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±ÛŒÙ…Ø§Ø±Ú© Ø§Ø² # Ø§Ù†ØªÙ‡Ø§
        remark_match = re.search(r'#([^\s]+)', link)
        if remark_match:
            remark = remark_match.group(1).strip()

        configs.append({
            "uuid": link.split("@")[0] if "@" in link else link.split("://")[1],
            "link": link,
            "location": location,
            "ping": ping,
            "type": proto.upper(),
            "remark": remark
        })

    # Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒ
    unique = {c['link']: c for c in configs}
    return list(unique.values())
